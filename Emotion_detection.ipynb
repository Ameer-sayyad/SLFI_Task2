{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihSTqc-XgJeM"
   },
   "source": [
    "#STEP 1 — Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN-vfuqgftx6",
    "outputId": "7701a97d-0bbe-479b-b26d-29133e913f39"
   },
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install transformers\n",
    "!pip install soundfile\n",
    "!pip install torch torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-vFFtxNgF7q"
   },
   "source": [
    "#STEP 2 — Mount Google Drive in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_t95YpagD5L",
    "outputId": "5ea7b0bc-1eec-40c8-99bd-641510663ce8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_dNedCHy4Ea"
   },
   "source": [
    "#Speech Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBB49DN-y72T",
    "outputId": "b423f3c6-37f1-4278-89ab-b70601bc17ba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# original dataset location (Google Drive)\n",
    "source_path = \"/content/drive/MyDrive/Emotion_dataset/TESS Toronto emotional speech set data\"\n",
    "\n",
    "# new split location (Colab runtime)\n",
    "split_path = \"/content/TESS_SPLIT\"\n",
    "\n",
    "train_dir = os.path.join(split_path, \"train\")\n",
    "test_dir = os.path.join(split_path, \"test\")\n",
    "\n",
    "emotions = [\"angry\",\"disgust\",\"fear\",\"happy\",\"ps\",\"sad\",\"neutral\"]\n",
    "\n",
    "# create train/test emotion folders\n",
    "for base in [train_dir, test_dir]:\n",
    "    for emo in emotions:\n",
    "        os.makedirs(os.path.join(base, emo), exist_ok=True)\n",
    "\n",
    "print(\"Folders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0TlDgIdzTRA",
    "outputId": "405dec19-e82b-4817-d173-52d2dae994ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_path = \"/content/drive/MyDrive/Emotion_dataset/TESS Toronto emotional speech set data\"\n",
    "\n",
    "for folder in os.listdir(source_path):\n",
    "    folder_path = os.path.join(source_path, folder)\n",
    "\n",
    "    for file in os.listdir(folder_path)[:5]:   # show first 5 files only\n",
    "        print(file)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mu_2cEACzdnQ",
    "outputId": "989fb7b1-2e08-4996-c805-d4d42147db6b"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "source_path = \"/content/drive/MyDrive/Emotion_dataset/TESS Toronto emotional speech set data\"\n",
    "\n",
    "emotion_files = defaultdict(lambda: {\"YAF\": [], \"OAF\": []})\n",
    "\n",
    "for folder in os.listdir(source_path):\n",
    "    folder_path = os.path.join(source_path, folder)\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "\n",
    "            speaker = file[:3]   # first 3 chars\n",
    "            emotion = file.split(\"_\")[-1].replace(\".wav\",\"\").lower()\n",
    "\n",
    "            full_path = os.path.join(folder_path, file)\n",
    "\n",
    "            if speaker in [\"YAF\", \"OAF\"]:\n",
    "                emotion_files[emotion][speaker].append(full_path)\n",
    "\n",
    "print(\"Grouping completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45B7n6wrzBAg",
    "outputId": "ea8d51e2-8aff-494e-c442-e8fa2c1f9dc9"
   },
   "outputs": [],
   "source": [
    "for emo in emotion_files:\n",
    "    print(\n",
    "        emo,\n",
    "        \"YAF:\", len(emotion_files[emo][\"YAF\"]),\n",
    "        \"OAF:\", len(emotion_files[emo][\"OAF\"])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVDUDomjzohb",
    "outputId": "3a8751ec-5ebb-4371-bf22-c065ef541fe5"
   },
   "outputs": [],
   "source": [
    "split_path = \"/content/TESS_SPLIT\"\n",
    "\n",
    "train_dir = os.path.join(split_path, \"train\")\n",
    "test_dir = os.path.join(split_path, \"test\")\n",
    "\n",
    "emotions = [\"angry\",\"disgust\",\"fear\",\"happy\",\"ps\",\"sad\",\"neutral\"]\n",
    "\n",
    "for base in [train_dir, test_dir]:\n",
    "    for emo in emotions:\n",
    "        os.makedirs(os.path.join(base, emo), exist_ok=True)\n",
    "\n",
    "print(\"Train/Test folders created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QE6hDbcdz1iO",
    "outputId": "0cb6fa29-0e35-440a-ef43-320b47bac9f6"
   },
   "outputs": [],
   "source": [
    "for emo in emotions:\n",
    "    train_count = len(os.listdir(os.path.join(train_dir, emo)))\n",
    "    test_count = len(os.listdir(os.path.join(test_dir, emo)))\n",
    "\n",
    "    print(f\"{emo} → Train: {train_count} | Test: {test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fw1Z_rxu0GTJ",
    "outputId": "3d29ec5a-2881-445a-c822-a7bc556d61d4"
   },
   "outputs": [],
   "source": [
    "train_base = \"/content/TESS_SPLIT/train\"\n",
    "test_base  = \"/content/TESS_SPLIT/test\"\n",
    "\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "# load train\n",
    "for emo in os.listdir(train_base):\n",
    "    emo_path = os.path.join(train_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        train_paths.append(os.path.join(emo_path, file))\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# load test\n",
    "for emo in os.listdir(test_base):\n",
    "    emo_path = os.path.join(test_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        test_paths.append(os.path.join(emo_path, file))\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "print(\"Train samples:\", len(train_paths))\n",
    "print(\"Test samples:\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ7BR57ckgj3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import HubertModel, Wav2Vec2FeatureExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "hubert_model = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NrtKpZAnAaB"
   },
   "outputs": [],
   "source": [
    "train_embed_dir = \"/content/hubert_train_embeddings\"\n",
    "test_embed_dir  = \"/content/hubert_test_embeddings\"\n",
    "\n",
    "os.makedirs(train_embed_dir, exist_ok=True)\n",
    "os.makedirs(test_embed_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4u21QVa0nH9n"
   },
   "outputs": [],
   "source": [
    "def extract_hubert(audio_path):\n",
    "\n",
    "    speech, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        speech,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    input_values = inputs.input_values.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = hubert_model(input_values)\n",
    "\n",
    "    # shape → [time_frames, 768]\n",
    "    embedding = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "    return embedding.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlRUO_re0MVm",
    "outputId": "ea3019ea-e5fe-4a8a-b3f8-0e3ed58ff59f"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for path in tqdm(train_paths):\n",
    "    emb = extract_hubert(path)\n",
    "\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    torch.save(emb, os.path.join(train_embed_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vZ0rZCz0il1",
    "outputId": "6738b2a4-62d6-4df1-c3ca-a043d22bb3ea"
   },
   "outputs": [],
   "source": [
    "for path in tqdm(test_paths):\n",
    "    emb = extract_hubert(path)\n",
    "\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    torch.save(emb, os.path.join(test_embed_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8rRTsHv00_J"
   },
   "outputs": [],
   "source": [
    "def load_train_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    return torch.load(os.path.join(train_embed_dir, file_name))\n",
    "\n",
    "def load_test_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    return torch.load(os.path.join(test_embed_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XAPjoiktSM2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmotionBiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionBiLSTM, self).__init__()\n",
    "\n",
    "        # BiLSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Dense classifier\n",
    "        self.fc = nn.Linear(256, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x shape → [T, 768]\n",
    "        x = x.unsqueeze(0)   # → [1, T, 768]\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)   # → [1, T, 256]\n",
    "\n",
    "        # mean pooling across time\n",
    "        pooled = lstm_out.mean(dim=1)   # → [1, 256]\n",
    "\n",
    "        output = self.fc(pooled)   # → [1, 7]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0_t9P7d02K8"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = EmotionBiLSTM().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXiDL4SO04nc",
    "outputId": "60fb2c76-ed29-44a0-a2c9-ec90b4e48bd3"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for path, label in zip(train_paths, train_labels):\n",
    "\n",
    "        features = load_train_embedding(path).unsqueeze(0).to(device)\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss:\", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "hq-QA0KW9aCI",
    "outputId": "6d388a0f-3eb6-4634-b66c-7fc3e58a5fa6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "results_path = \"/content/drive/MyDrive/Speech_Emotion_Project/Results\"\n",
    "plots_path = os.path.join(results_path, \"plots\")\n",
    "\n",
    "loss_values = [\n",
    "1157.85,914.07,727.33,623.13,506.66,452.66,343.60,261.29,201.86,\n",
    "145.06,134.16,89.48,67.02,54.13,56.74,46.16,27.09,16.44,24.37,\n",
    "11.89,15.61,12.94,9.97\n",
    "]\n",
    "\n",
    "# Save CSV\n",
    "df = pd.DataFrame({\"Epoch\": range(1,len(loss_values)+1),\n",
    "                   \"Loss\": loss_values})\n",
    "df.to_csv(os.path.join(results_path,\"speech_training_loss.csv\"), index=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(loss_values, marker='o')\n",
    "plt.title(\"Training Loss Curve - Speech Model (HuBERT + BiLSTM)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.savefig(os.path.join(plots_path,\"speech_loss_curve.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HvWYbvV7K48"
   },
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"/content/drive/MyDrive/Speech_Emotion_Project/final_hubert_bilstm.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wJcKFaS-r0Q"
   },
   "source": [
    "#Text sentence\n",
    "   ↓\n",
    "BERT tokenizer\n",
    "   ↓\n",
    "BERT embeddings\n",
    "   ↓\n",
    "CLS token representation\n",
    "   ↓\n",
    "Dense layer\n",
    "   ↓\n",
    "Softmax\n",
    "   ↓\n",
    "Emotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4lGCGpxDK3y"
   },
   "source": [
    "#STEP 1 — Build text dataset from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WIuoLDzlYkh",
    "outputId": "ca58899e-8c20-48ac-c01d-40d016fc51eb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_base = \"/content/TESS_SPLIT/train\"\n",
    "test_base  = \"/content/TESS_SPLIT/test\"\n",
    "\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "# load train data\n",
    "for emo in os.listdir(train_base):\n",
    "    emo_path = os.path.join(train_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        train_paths.append(os.path.join(emo_path, file))\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# load test data\n",
    "for emo in os.listdir(test_base):\n",
    "    emo_path = os.path.join(test_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        test_paths.append(os.path.join(emo_path, file))\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "print(\"Train samples:\", len(train_paths))\n",
    "print(\"Test samples:\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2BV58jz-u8v",
    "outputId": "ce4c12e9-483d-40d8-bd3e-b7ae3a34fcd3"
   },
   "outputs": [],
   "source": [
    "def build_text_dataset(paths, labels):\n",
    "    texts = []\n",
    "\n",
    "    for path in paths:\n",
    "        file = path.split(\"/\")[-1]\n",
    "        word = file.split(\"_\")[1]   # extract main word\n",
    "\n",
    "        sentence = f\"say the word {word}\"\n",
    "        texts.append(sentence)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels_text = build_text_dataset(train_paths, train_labels)\n",
    "test_texts, test_labels_text = build_text_dataset(test_paths, test_labels)\n",
    "\n",
    "print(train_texts[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okteAY3d-s3Z",
    "outputId": "13558e0f-2cac-409f-e5a3-071ab69a8d65"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J532RkROlycw",
    "outputId": "3be64fa7-6567-410e-cb8b-4ec36a00c255"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "f785774d12194ef7ac7cc3eb3a036715",
      "f150cba47a2947d598f87c43fad51c80",
      "9b8acafbecae48c3b2356a626f0ce878",
      "97bb1dc950bc48aeb32bd46b257666a3",
      "a8a64e859e62495bae4be59644e6ae70",
      "7ce1895bfa5d40fd8d784cde5861db7d",
      "132abad1c3d74f419aace26192971965",
      "f73e0d43de034baf81c276a44d8d7149",
      "fea3ebc984da482cbd126d376cd35008",
      "c6c75cc0b81f485f8df5d90d08c55203",
      "ee0c6f25a1bc4f3bb43964dde4a0f21b"
     ]
    },
    "id": "TOkBwOitDW63",
    "outputId": "ab4624a5-1bc9-4354-ab88-f3c0973bf9d8"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeu0C-4D-xmz",
    "outputId": "a29b9f6d-6671-4126-f075-085cceea8117"
   },
   "outputs": [],
   "source": [
    "sample_text = train_texts[0]\n",
    "\n",
    "inputs = tokenizer(sample_text,\n",
    "                   return_tensors=\"pt\",\n",
    "                   truncation=True,\n",
    "                   padding=True,\n",
    "                   max_length=16).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(**inputs)\n",
    "\n",
    "cls_embedding = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "print(\"Embedding shape:\", cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LeRy8JKDUOe"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextEmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFukyNRQDlMs"
   },
   "outputs": [],
   "source": [
    "text_model = TextEmotionClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(text_model.parameters(), lr=2e-5)\n",
    "\n",
    "epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwTx3ChyEFl2",
    "outputId": "fc9b3355-25ab-4ed9-e599-33869460427d"
   },
   "outputs": [],
   "source": [
    "epoch_losses_text = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    text_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for text, label in zip(train_texts, train_labels_text):\n",
    "\n",
    "        inputs = tokenizer(text,\n",
    "                           return_tensors=\"pt\",\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=16).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "\n",
    "        cls_embedding = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        preds = text_model(cls_embedding)\n",
    "        loss = criterion(preds, label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_losses_text.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1} Loss:\", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVfjYlawHNhq",
    "outputId": "dea6ae24-d5e6-47b0-9269-8a488aefcd0b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "text_model.eval()\n",
    "preds_text = []\n",
    "\n",
    "for text in test_texts:\n",
    "\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors=\"pt\",\n",
    "                       truncation=True,\n",
    "                       padding=True,\n",
    "                       max_length=16).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    cls_embedding = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "    pred = torch.argmax(text_model(cls_embedding), dim=1).item()\n",
    "    preds_text.append(pred)\n",
    "\n",
    "acc_text = accuracy_score(test_labels_text, preds_text)\n",
    "\n",
    "print(\"Text Model Accuracy:\", acc_text)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(test_labels_text, preds_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "clZtNvlUH9uA",
    "outputId": "a4d256ef-2cc9-46d1-a1ab-3dc530640d25"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epoch_losses_text, marker='o')\n",
    "plt.title(\"Training Loss Curve - Text Model (BERT)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.savefig(os.path.join(plots_path, \"text_loss_curve.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FupYUKGYJsZm"
   },
   "source": [
    "#Multimodal Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nsotn8dFJ2iz"
   },
   "source": [
    "#STEP 2 — Fusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yysve5MIPMO",
    "outputId": "b1f57af1-25ad-4b83-b593-2f21c26fb76b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OTBrRBVsI7a",
    "outputId": "222f2b41-1f65-4e7f-91be-be074fabf945"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_base = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/train\"\n",
    "test_base  = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/test\"\n",
    "\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "# rebuild train list\n",
    "for emo in os.listdir(train_base):\n",
    "    emo_path = os.path.join(train_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        train_paths.append(os.path.join(emo_path, file))\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# rebuild test list\n",
    "for emo in os.listdir(test_base):\n",
    "    emo_path = os.path.join(test_base, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        test_paths.append(os.path.join(emo_path, file))\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "print(\"Train:\", len(train_paths))\n",
    "print(\"Test:\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugvHuvfbsiJc",
    "outputId": "11494cba-b760-4b71-c055-bbac2df77748"
   },
   "outputs": [],
   "source": [
    "def build_text_dataset(paths, labels):\n",
    "    texts = []\n",
    "\n",
    "    for path in paths:\n",
    "        file = path.split(\"/\")[-1]\n",
    "        word = file.split(\"_\")[1]\n",
    "        sentence = f\"say the word {word}\"\n",
    "        texts.append(sentence)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels_text = build_text_dataset(train_paths, train_labels)\n",
    "test_texts, test_labels_text = build_text_dataset(test_paths, test_labels)\n",
    "\n",
    "print(train_texts[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mH2dC3maJ463"
   },
   "outputs": [],
   "source": [
    "train_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_train_embeddings\"\n",
    "test_embed_dir  = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_test_embeddings\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "7a532000b91b4f81a2ffc88194aceb0a",
      "13083f74088b4162914f26c17664523a",
      "5b23053f72f545a19cc8272f2e6f78b4",
      "523eb921fb16400189615e70b56666c1",
      "dbeb5e994f804fb3a3ae629589632fd0",
      "aa2158a1d8e04d36952292042d68a097",
      "5bf43ed24deb41c3b64fa8b10a8b39dc",
      "d81121f83920456abc42e54c19e59852",
      "eb46403f614c4ab7aceb3b68cd073134",
      "71b5d20a29b346e19296796c4046f843",
      "4043881fd0b14d768bca5ec2b7303e11"
     ]
    },
    "id": "OUd6JW0FstnT",
    "outputId": "6b6e86ae-92c9-43a7-acab-12c9ecdfc59b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wurgizsStZjP"
   },
   "outputs": [],
   "source": [
    "def load_train_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    emb_path = os.path.join(train_embed_dir, file_name)\n",
    "\n",
    "    if os.path.exists(emb_path):\n",
    "        return torch.load(emb_path)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_test_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    emb_path = os.path.join(test_embed_dir, file_name)\n",
    "\n",
    "    if os.path.exists(emb_path):\n",
    "        return torch.load(emb_path)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6YTBVLvtdMk"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FusionEmotionModel(nn.Module):\n",
    "    def __init__(self, speech_dim=768, text_dim=768, num_classes=7):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(speech_dim + text_dim, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, speech_emb, text_emb):\n",
    "        fused = torch.cat((speech_emb, text_emb), dim=1)\n",
    "        x = self.fc1(fused)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwgEY91Nti2k"
   },
   "outputs": [],
   "source": [
    "fusion_model = FusionEmotionModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqgFpOQJsy1b",
    "outputId": "36bb3114-e063-4d1b-ee30-997d66b1b6b6"
   },
   "outputs": [],
   "source": [
    "epoch_losses_fusion = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    fusion_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for path, text, label in zip(train_paths, train_texts, train_labels):\n",
    "\n",
    "        speech_emb = load_train_embedding(path)\n",
    "        if speech_emb is None:\n",
    "            continue\n",
    "\n",
    "        speech_emb = speech_emb.unsqueeze(0).to(device)\n",
    "        speech_emb = speech_emb.mean(dim=1)\n",
    "\n",
    "        inputs = tokenizer(text,\n",
    "                           return_tensors=\"pt\",\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=16).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "\n",
    "        text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        preds = fusion_model(speech_emb, text_emb)\n",
    "        loss = criterion(preds, label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_losses_fusion.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1} Loss:\", total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpyhtTboy-7g",
    "outputId": "8f8a0028-05d2-438b-f5ea-1483a02795c0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "fusion_model.eval()\n",
    "preds_fusion = []\n",
    "\n",
    "for path, text in zip(test_paths, test_texts):\n",
    "\n",
    "    speech_emb = load_test_embedding(path)\n",
    "    if speech_emb is None:\n",
    "        continue\n",
    "\n",
    "    speech_emb = speech_emb.unsqueeze(0).to(device)\n",
    "    speech_emb = speech_emb.mean(dim=1)\n",
    "\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors=\"pt\",\n",
    "                       truncation=True,\n",
    "                       padding=True,\n",
    "                       max_length=16).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "    pred = torch.argmax(fusion_model(speech_emb, text_emb), dim=1).item()\n",
    "    preds_fusion.append(pred)\n",
    "\n",
    "acc_fusion = accuracy_score(test_labels[:len(preds_fusion)], preds_fusion)\n",
    "\n",
    "print(\"Fusion Model Accuracy:\", acc_fusion)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(test_labels[:len(preds_fusion)], preds_fusion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8S3o4-gB0GbA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Epoch\": list(range(1, len(epoch_losses_fusion)+1)),\n",
    "    \"Loss\": epoch_losses_fusion\n",
    "}).to_csv(os.path.join(results_path, \"fusion_training_loss.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "fTYBHI4K0I_E",
    "outputId": "98c8c9d8-2fd0-43db-9e01-ee61b7606d02"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epoch_losses_fusion, marker='o')\n",
    "plt.title(\"Fusion Model Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.savefig(os.path.join(plots_path, \"fusion_loss_curve.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpNzqh3uvLpO"
   },
   "source": [
    "#speech output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QXv2vcg1GCG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmotionBiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=128, num_layers=1, num_classes=7):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out.mean(dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnqyV7lp2UY8"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSgBS_yR2XqF",
    "outputId": "bfbc3649-b8c8-47c1-93f4-bee3340bee85"
   },
   "outputs": [],
   "source": [
    "speech_model_path = \"/content/drive/MyDrive/Speech_Emotion_Project/final_hubert_bilstm.pt\"\n",
    "\n",
    "model = EmotionBiLSTM().to(device)\n",
    "model.load_state_dict(torch.load(speech_model_path))\n",
    "model.eval()\n",
    "\n",
    "print(\"Speech model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3wFAPd02Z3_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_test_embeddings\"\n",
    "\n",
    "def load_test_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\", \".pt\")\n",
    "    return torch.load(os.path.join(test_embed_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdOYRIjx2cKE",
    "outputId": "7bfe2098-9e71-4396-a88f-89350e31bb55"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for path in test_paths:\n",
    "    features = load_test_embedding(path).unsqueeze(0).to(device)\n",
    "    outputs = model(features)\n",
    "    pred = torch.argmax(outputs, dim=1).item()\n",
    "    preds.append(pred)\n",
    "\n",
    "print(\"Predictions:\", len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo1ucCGX2iNl",
    "outputId": "dc65b6b2-a31c-45f0-a843-cc55b4492f35"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "speech_report = classification_report(test_labels, preds)\n",
    "print(speech_report)\n",
    "\n",
    "results_path = \"/content/drive/MyDrive/Speech_Emotion_Project/Results\"\n",
    "\n",
    "with open(results_path + \"/speech_classification_report.txt\", \"w\") as f:\n",
    "    f.write(speech_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InIHLjsi3WvB"
   },
   "outputs": [],
   "source": [
    "speech_train_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "train_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_train_embeddings\"\n",
    "train_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/train\"\n",
    "model_save_path = \"/content/drive/MyDrive/project/models/speech_pipeline/speech_model.pt\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TRAIN DATA\n",
    "# ---------------------------\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "for emo in os.listdir(train_split_path):\n",
    "    emo_path = os.path.join(train_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        train_paths.append(os.path.join(emo_path, file))\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD EMBEDDINGS\n",
    "# ---------------------------\n",
    "def load_train_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\",\".pt\")\n",
    "    return torch.load(os.path.join(train_embed_dir,file_name))\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL\n",
    "# ---------------------------\n",
    "class EmotionBiLSTM(nn.Module):\n",
    "    def __init__(self,input_dim=768,hidden_dim=128,num_layers=1,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out = out[:,-1,:]\n",
    "        return self.fc(out)\n",
    "\n",
    "model = EmotionBiLSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "# ---------------------------\n",
    "# TRAIN LOOP\n",
    "# ---------------------------\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for path,label in tqdm(zip(train_paths,train_labels), total=len(train_paths)):\n",
    "\n",
    "        features = load_train_embedding(path).unsqueeze(0).to(device)\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs,label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss:\", total_loss)\n",
    "\n",
    "# ---------------------------\n",
    "# SAVE MODEL\n",
    "# ---------------------------\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(\"Speech model saved.\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHu_LEAK3bOP"
   },
   "outputs": [],
   "source": [
    "speech_test_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "model_path = \"/content/drive/MyDrive/project/models/speech_pipeline/speech_model.pt\"\n",
    "test_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_test_embeddings\"\n",
    "test_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/test\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TEST DATA\n",
    "# ---------------------------\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for emo in os.listdir(test_split_path):\n",
    "    emo_path = os.path.join(test_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        test_paths.append(os.path.join(emo_path, file))\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD EMBEDDINGS\n",
    "# ---------------------------\n",
    "def load_test_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\",\".pt\")\n",
    "    return torch.load(os.path.join(test_embed_dir,file_name))\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL\n",
    "# ---------------------------\n",
    "class EmotionBiLSTM(nn.Module):\n",
    "    def __init__(self,input_dim=768,hidden_dim=128,num_layers=1,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out = out[:,-1,:]\n",
    "        return self.fc(out)\n",
    "\n",
    "model = EmotionBiLSTM().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# TEST LOOP\n",
    "# ---------------------------\n",
    "preds = []\n",
    "\n",
    "for path in test_paths:\n",
    "    features = load_test_embedding(path).unsqueeze(0).to(device)\n",
    "    outputs = model(features)\n",
    "    pred = torch.argmax(outputs,dim=1).item()\n",
    "    preds.append(pred)\n",
    "\n",
    "# ---------------------------\n",
    "# RESULTS\n",
    "# ---------------------------\n",
    "acc = accuracy_score(test_labels,preds)\n",
    "\n",
    "print(\"Speech Test Accuracy:\",acc)\n",
    "print(\"\\\\nClassification Report:\\\\n\")\n",
    "print(classification_report(test_labels,preds))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbbs0UmP3c86"
   },
   "outputs": [],
   "source": [
    "text_train_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "train_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/train\"\n",
    "model_save_path = \"/content/drive/MyDrive/project/models/text_pipeline/text_model.pt\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TRAIN DATA\n",
    "# ---------------------------\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "for emo in os.listdir(train_split_path):\n",
    "    emo_path = os.path.join(train_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        word = file.split(\"_\")[1]\n",
    "        sentence = f\"say the word {word}\"\n",
    "\n",
    "        train_texts.append(sentence)\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD BERT\n",
    "# ---------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# TEXT CLASSIFIER\n",
    "# ---------------------------\n",
    "class TextEmotionClassifier(nn.Module):\n",
    "    def __init__(self,input_dim=768,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TextEmotionClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=2e-5)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# ---------------------------\n",
    "# TRAIN LOOP\n",
    "# ---------------------------\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for text,label in tqdm(zip(train_texts,train_labels), total=len(train_texts)):\n",
    "\n",
    "        inputs = tokenizer(text,\n",
    "                           return_tensors=\"pt\",\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=16).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "\n",
    "        text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        preds = model(text_emb)\n",
    "        loss = criterion(preds,label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss:\", total_loss)\n",
    "\n",
    "# ---------------------------\n",
    "# SAVE MODEL\n",
    "# ---------------------------\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(\"Text model saved.\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6HK7Fdm3fMq"
   },
   "outputs": [],
   "source": [
    "text_test_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "model_path = \"/content/drive/MyDrive/project/models/text_pipeline/text_model.pt\"\n",
    "test_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/test\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TEST DATA\n",
    "# ---------------------------\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "\n",
    "for emo in os.listdir(test_split_path):\n",
    "    emo_path = os.path.join(test_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        word = file.split(\"_\")[1]\n",
    "        sentence = f\"say the word {word}\"\n",
    "\n",
    "        test_texts.append(sentence)\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD BERT\n",
    "# ---------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL\n",
    "# ---------------------------\n",
    "class TextEmotionClassifier(nn.Module):\n",
    "    def __init__(self,input_dim=768,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = TextEmotionClassifier().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# TEST LOOP\n",
    "# ---------------------------\n",
    "preds = []\n",
    "\n",
    "for text in test_texts:\n",
    "\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors=\"pt\",\n",
    "                       truncation=True,\n",
    "                       padding=True,\n",
    "                       max_length=16).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "    pred = torch.argmax(model(text_emb),dim=1).item()\n",
    "    preds.append(pred)\n",
    "\n",
    "# ---------------------------\n",
    "# RESULTS\n",
    "# ---------------------------\n",
    "acc = accuracy_score(test_labels,preds)\n",
    "\n",
    "print(\"Text Test Accuracy:\",acc)\n",
    "print(\"\\\\nClassification Report:\\\\n\")\n",
    "print(classification_report(test_labels,preds))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWowOhcP3h2v"
   },
   "outputs": [],
   "source": [
    "fusion_train_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "train_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/train\"\n",
    "train_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_train_embeddings\"\n",
    "model_save_path = \"/content/drive/MyDrive/project/models/fusion_pipeline/fusion_model.pt\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TRAIN DATA\n",
    "# ---------------------------\n",
    "train_paths = []\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "for emo in os.listdir(train_split_path):\n",
    "    emo_path = os.path.join(train_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "        path = os.path.join(emo_path, file)\n",
    "\n",
    "        word = file.split(\"_\")[1]\n",
    "        sentence = f\"say the word {word}\"\n",
    "\n",
    "        train_paths.append(path)\n",
    "        train_texts.append(sentence)\n",
    "        train_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD EMBEDDINGS\n",
    "# ---------------------------\n",
    "def load_train_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\",\".pt\")\n",
    "    return torch.load(os.path.join(train_embed_dir,file_name))\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD BERT\n",
    "# ---------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# FUSION MODEL\n",
    "# ---------------------------\n",
    "class FusionEmotionModel(nn.Module):\n",
    "    def __init__(self,speech_dim=768,text_dim=768,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(speech_dim+text_dim,256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256,num_classes)\n",
    "\n",
    "    def forward(self,speech_emb,text_emb):\n",
    "        fused = torch.cat((speech_emb,text_emb),dim=1)\n",
    "        x = self.fc1(fused)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = FusionEmotionModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "epochs = 12\n",
    "\n",
    "# ---------------------------\n",
    "# TRAIN LOOP\n",
    "# ---------------------------\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for path,text,label in tqdm(zip(train_paths,train_texts,train_labels),\n",
    "                                total=len(train_paths)):\n",
    "\n",
    "        # speech embedding\n",
    "        speech_emb = load_train_embedding(path).unsqueeze(0).to(device)\n",
    "        speech_emb = speech_emb.mean(dim=1)\n",
    "\n",
    "        # text embedding\n",
    "        inputs = tokenizer(text,\n",
    "                           return_tensors=\"pt\",\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=16).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "\n",
    "        text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "        label_tensor = torch.tensor([label]).to(device)\n",
    "\n",
    "        preds = model(speech_emb,text_emb)\n",
    "        loss = criterion(preds,label_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss:\",total_loss)\n",
    "\n",
    "# ---------------------------\n",
    "# SAVE MODEL\n",
    "# ---------------------------\n",
    "torch.save(model.state_dict(),model_save_path)\n",
    "print(\"Fusion model saved.\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFSvV7MS3kQm"
   },
   "outputs": [],
   "source": [
    "fusion_test_code = '''\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ---------------------------\n",
    "# PATHS\n",
    "# ---------------------------\n",
    "model_path = \"/content/drive/MyDrive/project/models/fusion_pipeline/fusion_model.pt\"\n",
    "test_split_path = \"/content/drive/MyDrive/Speech_Emotion_Project/TESS_SPLIT/test\"\n",
    "test_embed_dir = \"/content/drive/MyDrive/Speech_Emotion_Project/hubert_test_embeddings\"\n",
    "\n",
    "# ---------------------------\n",
    "# DEVICE\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------------\n",
    "# EMOTION MAP\n",
    "# ---------------------------\n",
    "emotion_map = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"ps\":4,\n",
    "    \"sad\":5,\n",
    "    \"neutral\":6\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD TEST DATA\n",
    "# ---------------------------\n",
    "test_paths = []\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "\n",
    "for emo in os.listdir(test_split_path):\n",
    "    emo_path = os.path.join(test_split_path, emo)\n",
    "\n",
    "    for file in os.listdir(emo_path):\n",
    "\n",
    "        path = os.path.join(emo_path,file)\n",
    "        word = file.split(\"_\")[1]\n",
    "        sentence = f\"say the word {word}\"\n",
    "\n",
    "        test_paths.append(path)\n",
    "        test_texts.append(sentence)\n",
    "        test_labels.append(emotion_map[emo])\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD EMBEDDINGS\n",
    "# ---------------------------\n",
    "def load_test_embedding(path):\n",
    "    file_name = path.split(\"/\")[-1].replace(\".wav\",\".pt\")\n",
    "    return torch.load(os.path.join(test_embed_dir,file_name))\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD BERT\n",
    "# ---------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL\n",
    "# ---------------------------\n",
    "class FusionEmotionModel(nn.Module):\n",
    "    def __init__(self,speech_dim=768,text_dim=768,num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(speech_dim+text_dim,256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256,num_classes)\n",
    "\n",
    "    def forward(self,speech_emb,text_emb):\n",
    "        fused = torch.cat((speech_emb,text_emb),dim=1)\n",
    "        x = self.fc1(fused)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = FusionEmotionModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# TEST LOOP\n",
    "# ---------------------------\n",
    "preds = []\n",
    "\n",
    "for path,text in zip(test_paths,test_texts):\n",
    "\n",
    "    speech_emb = load_test_embedding(path).unsqueeze(0).to(device)\n",
    "    speech_emb = speech_emb.mean(dim=1)\n",
    "\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors=\"pt\",\n",
    "                       truncation=True,\n",
    "                       padding=True,\n",
    "                       max_length=16).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    text_emb = outputs.last_hidden_state[:,0,:]\n",
    "\n",
    "    pred = torch.argmax(model(speech_emb,text_emb),dim=1).item()\n",
    "    preds.append(pred)\n",
    "\n",
    "# ---------------------------\n",
    "# RESULTS\n",
    "# ---------------------------\n",
    "acc = accuracy_score(test_labels,preds)\n",
    "\n",
    "print(\"Fusion Test Accuracy:\",acc)\n",
    "print(\"\\\\nClassification Report:\\\\n\")\n",
    "print(classification_report(test_labels,preds))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "Nj5DAVLnCoKB",
    "outputId": "b1fe07e7-7ab0-4305-c883-0f18279ef257"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "emotion_names = [\n",
    "    \"angry\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"happy\",\n",
    "    \"pleasant_surprise\",\n",
    "    \"sad\",\n",
    "    \"neutral\"\n",
    "]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "temp_2d = tsne.fit_transform(temporal_features)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0,1,7))\n",
    "\n",
    "for i in range(7):\n",
    "    idx = np.where(np.array(test_labels) == i)\n",
    "    plt.scatter(\n",
    "        temp_2d[idx,0],\n",
    "        temp_2d[idx,1],\n",
    "        label=emotion_names[i],\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "plt.title(\"Temporal Modelling Representation (BiLSTM)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "BZfGvwTtDKdl",
    "outputId": "d4bf6646-2054-4967-852f-208d86a4c918"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "emotion_names = [\n",
    "    \"angry\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"happy\",\n",
    "    \"pleasant_surprise\",\n",
    "    \"sad\",\n",
    "    \"neutral\"\n",
    "]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "context_2d = tsne.fit_transform(context_features)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0,1,7))\n",
    "\n",
    "for i in range(7):\n",
    "    idx = np.where(np.array(test_labels) == i)\n",
    "    plt.scatter(\n",
    "        context_2d[idx,0],\n",
    "        context_2d[idx,1],\n",
    "        label=emotion_names[i],\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "plt.title(\"Contextual Modelling Representation (BERT)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "FLRvZb93EI3U",
    "outputId": "77ada89a-6453-4a41-e827-f56c6f32d8b3"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "emotion_names = [\n",
    "    \"angry\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"happy\",\n",
    "    \"pleasant_surprise\",\n",
    "    \"sad\",\n",
    "    \"neutral\"\n",
    "]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "fusion_2d = tsne.fit_transform(fusion_features)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0,1,7))\n",
    "\n",
    "for i in range(7):\n",
    "    idx = np.where(np.array(test_labels) == i)\n",
    "    plt.scatter(\n",
    "        fusion_2d[idx,0],\n",
    "        fusion_2d[idx,1],\n",
    "        label=emotion_names[i],\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "plt.title(\"Fusion Representation Clusters (Speech + Text)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac99zGu1FE1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
